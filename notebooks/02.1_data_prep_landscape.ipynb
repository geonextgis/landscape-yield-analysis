{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5d4652",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from rasterio import features\n",
    "from shapely import wkt\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from itertools import product\n",
    "import pylandstats as pls\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded535e1",
   "metadata": {},
   "source": [
    "## Define the Parameters (useful for command line run using papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c470c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP = 'ww'\n",
    "DISTANCE = 2.5\n",
    "EPSG = 25832\n",
    "\n",
    "# Path of the directories\n",
    "WORK_DIR = '/beegfs/halder/GITHUB/RESEARCH/landscape-yield-analysis/'\n",
    "os.chdir(WORK_DIR)\n",
    "MAIN_DATA_DIR = '/beegfs/halder/DATA/'\n",
    "WORK_DATA_DIR = os.path.join(WORK_DIR, 'data')\n",
    "WORK_TEMP_DIR = os.path.join(WORK_DIR, 'temp')\n",
    "\n",
    "OUT_DIR = os.path.join(WORK_DIR, 'output', str(DISTANCE), CROP)\n",
    "if os.path.exists(OUT_DIR) == False:\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    print('Output directory successfully created!')\n",
    "else:\n",
    "    print('Output directory already existed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354c790",
   "metadata": {},
   "source": [
    "## Load Hexagonal Grid for Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to grid shapefile\n",
    "GRID_PATH = os.path.join(WORK_DATA_DIR, 'VECTOR', f'DE_Hexbins_{DISTANCE}sqkm_EPSG_{EPSG}.shp')\n",
    "\n",
    "# Load grid as a GeoDataFrame and retain relevant columns\n",
    "grids_gdf = gpd.read_file(GRID_PATH)\n",
    "grids_gdf = grids_gdf[['id', 'geometry']]\n",
    "grids_gdf['id'] = grids_gdf['id'].astype(int)\n",
    "\n",
    "print('Successfully read the grids!')\n",
    "grids_gdf.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3caafd",
   "metadata": {},
   "source": [
    "## Calculate Euclidean Distance from Cropland to Other LULC Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408dc95d",
   "metadata": {},
   "source": [
    "### Reproject and Resample the LULC Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Cropland layer\n",
    "lulc_path = os.path.join(MAIN_DATA_DIR, 'DE_ESA_WORLDCOVER_10M_2021_V200', 'ESA_WorldCover_2021_DE_WGS84.tif')\n",
    "cropland_path = os.path.join(MAIN_DATA_DIR, 'DE_Crop_Types_2017_2021', f'{CROP}_mask_combined.tif')\n",
    "\n",
    "# Open source raster\n",
    "with rio.open(cropland_path) as src:\n",
    "    cropland = src.read(1)\n",
    "    cropland_profile = src.profile\n",
    "    cropland_transform = src.transform\n",
    "    cropland_crs = src.crs\n",
    "    cropland_shape = (src.height, src.width)\n",
    "    \n",
    "# with rio.open(lulc_path) as src:\n",
    "#     lulc = src.read(1)\n",
    "#     lulc_transform = src.transform\n",
    "#     lulc_crs = src.crs\n",
    "    \n",
    "#     # Create an empty array for resampled data\n",
    "#     lulc_resampled = np.empty(cropland_shape, dtype=lulc.dtype)\n",
    "\n",
    "#     # Reproject & resample LULC to match cropland grid\n",
    "#     reproject(\n",
    "#         source=lulc,\n",
    "#         destination=lulc_resampled,\n",
    "#         src_transform=lulc_transform,\n",
    "#         src_crs=lulc_crs,\n",
    "#         dst_transform=cropland_transform,\n",
    "#         dst_crs=cropland_crs,\n",
    "#         resampling=Resampling.nearest\n",
    "#     )\n",
    "\n",
    "# # Save the resampled raster\n",
    "# cropland_profile.update(\n",
    "#     dtype=lulc_resampled.dtype,\n",
    "#     count=1,\n",
    "#     compress='lzw'\n",
    "# )\n",
    "\n",
    "# with rio.open(os.path.join(WORK_TEMP_DIR, 'lulc_resampled.tif'), 'w', **cropland_profile) as dst:\n",
    "#     dst.write(lulc_resampled, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6ed1",
   "metadata": {},
   "source": [
    "### Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b548e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LULC codes\n",
    "lulc_class_code = {\n",
    "    'tree_cover':10,\n",
    "    'shrubland': 20,\n",
    "    'grassland': 30,\n",
    "    'builtup': 50,\n",
    "    'bare': 60,\n",
    "    'water': 80,\n",
    "    'wetland': 90,\n",
    "    'mangroves': 95,\n",
    "    'moss_lichen': 100\n",
    "}\n",
    "\n",
    "def dist_to_lulc_per_hexbin(task):\n",
    "    hex_id, geometry_wkt, lulc, lulc_code = task\n",
    "    geometry = wkt.loads(geometry_wkt)\n",
    "    buffer_poly = geometry.buffer(buffer_distance)\n",
    "\n",
    "    # Open rasters inside worker\n",
    "    with rio.open(os.path.join(WORK_TEMP_DIR, 'lulc_resampled.tif')) as lulc_src, \\\n",
    "         rio.open(cropland_path) as crop_src:\n",
    "\n",
    "        # Mask LULC and cropland inside buffer\n",
    "        lulc_img, lulc_transform = mask(lulc_src, [buffer_poly], crop=True)\n",
    "        crop_img, _ = mask(crop_src, [buffer_poly], crop=True)\n",
    "\n",
    "        lulc_data = lulc_img[0]\n",
    "        cropland_data = crop_img[0]\n",
    "        cropland_data = np.where(cropland_data>0, 1, 0)\n",
    "\n",
    "        # If no target LULC class, return NaN\n",
    "        if not np.any(lulc_data == lulc_code):\n",
    "            return {'id': hex_id, f'mean_dist_to_{lulc}': np.nan, f'median_dist_to_{lulc}': np.nan}\n",
    "\n",
    "        # Compute distance transform\n",
    "        lulc_mask = (lulc_data == lulc_code)\n",
    "        dist_map = distance_transform_edt(~lulc_mask) * pixel_size\n",
    "\n",
    "        # Cropland mask in buffer\n",
    "        cropland_mask_in_buffer = (cropland_data == 1)\n",
    "\n",
    "        # Rasterize hexbin geometry into buffer extent\n",
    "        hexbin_mask_in_buffer = features.rasterize(\n",
    "            [(geometry, 1)],\n",
    "            out_shape=dist_map.shape,\n",
    "            transform=lulc_transform,\n",
    "            fill=0,\n",
    "            dtype=np.uint8\n",
    "        ).astype(bool)\n",
    "\n",
    "        # Cropland pixels inside hexbin (all in buffer extent)\n",
    "        cropland_in_hexbin_in_buffer = cropland_mask_in_buffer & hexbin_mask_in_buffer\n",
    "\n",
    "        # Apply mask to dist_map\n",
    "        dist_cropland_in_hexbin = np.where(cropland_in_hexbin_in_buffer, dist_map, np.nan)\n",
    "\n",
    "        mean_dist = np.nanmean(dist_cropland_in_hexbin)\n",
    "        median_dist = np.nanmedian(dist_cropland_in_hexbin)\n",
    "\n",
    "        return {'id': hex_id, f'mean_dist_to_{lulc}': mean_dist, f'median_dist_to_{lulc}': median_dist}\n",
    "\n",
    "buffer_distance = (DISTANCE * 1000) // 2\n",
    "pixel_size = 10\n",
    "\n",
    "# for lulc, lulc_code in lulc_class_code.items():\n",
    "#     print('*' * 20 + f' {lulc} ' + '*' * 20)\n",
    "#     # Prepare list of tasks: hex_id and geometry WKT\n",
    "#     tasks = [(row['id'], row.geometry.wkt, lulc, lulc_code) for idx, row in grids_gdf.iterrows()]\n",
    "\n",
    "#     # Parallel execution\n",
    "#     results = []\n",
    "#     with ProcessPoolExecutor(max_workers=50) as executor:\n",
    "#         for res in tqdm(executor.map(dist_to_lulc_per_hexbin, tasks), total=len(tasks), desc='Processing hexbins'):\n",
    "#             results.append(res)\n",
    "\n",
    "#     results = pd.DataFrame(results)\n",
    "#     results.to_csv(os.path.join(WORK_TEMP_DIR, f'distance_to_{lulc}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a99db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the data into a single dataframe\n",
    "# distance_file_paths = glob(os.path.join(WORK_TEMP_DIR, 'distance_to*'))\n",
    "# distance_to_lulc = pd.DataFrame()\n",
    "\n",
    "# for path in distance_file_paths:\n",
    "#     df = pd.read_csv(path)\n",
    "    \n",
    "#     if distance_to_lulc.empty:\n",
    "#         distance_to_lulc = df\n",
    "#     else:\n",
    "#         distance_to_lulc = pd.merge(left=distance_to_lulc, right=df, on='id', how='inner')\n",
    "\n",
    "# # Save the data\n",
    "# distance_to_lulc.to_csv(os.path.join(OUT_DIR, 'distance_to_lulc.csv'), index=False)\n",
    "# print(distance_to_lulc.shape)\n",
    "# distance_to_lulc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b851743",
   "metadata": {},
   "source": [
    "## Compute Landscape Metrics Using PyLandStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93422e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Resampled ESA WorldCover LULC raster (10 m resolution, 2021)\n",
    "lulc_path = os.path.join(WORK_TEMP_DIR, 'lulc_resampled.tif')\n",
    "\n",
    "# Create ZonalAnalysis object for computing landscape metrics per grid zone\n",
    "za = pls.ZonalAnalysis(\n",
    "    lulc_path,  # Use the reprojected raster\n",
    "    zones=grids_gdf,\n",
    "    zone_index='id',\n",
    "    neighborhood_rule=8       # 8-neighbor connectivity for landscape pattern analysis\n",
    ")\n",
    "\n",
    "# Compute class-level metrics (per land cover class) for each zone\n",
    "class_metrics_df = za.compute_class_metrics_df().reset_index()\n",
    "class_metrics_df.to_csv(os.path.join(os.path.dirname(OUT_DIR), 'class_metrics.csv'), index=False)\n",
    "\n",
    "# Compute landscape-level metrics (overall structure) for each zone\n",
    "landscape_metrics_df = za.compute_landscape_metrics_df().reset_index()\n",
    "landscape_metrics_df.to_csv(os.path.join(os.path.dirname(OUT_DIR), 'landscape_metrics.csv'), index=False)\n",
    "\n",
    "print('Landscape metrics computation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979fa7b",
   "metadata": {},
   "source": [
    "## Compute Crop Metrics Using PyLandStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c20a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2017, 2022)\n",
    "\n",
    "for year in tqdm(years):\n",
    "    # Path to crop type raster (10 m resolution)\n",
    "    crop_file_path = os.path.join(MAIN_DATA_DIR, 'DE_Crop_Types_2017_2021', f'DE_Crop_Type_{year}.tif')\n",
    "    reprojected_raster_path = os.path.join(WORK_TEMP_DIR, f'DE_Crop_Type_{year}.tif')\n",
    "\n",
    "    # Target CRS (Coordinate Reference System)\n",
    "    dst_crs = f'EPSG:{EPSG}'\n",
    "\n",
    "    # Open source raster\n",
    "    with rio.open(crop_file_path) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        \n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        # Write reprojected raster\n",
    "        with rio.open(reprojected_raster_path, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rio.band(src, i),\n",
    "                    destination=rio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )\n",
    "                \n",
    "    print('Raster Saved Successfully!')\n",
    "\n",
    "    # Collect valid zone indices\n",
    "    valid_indices = []\n",
    "\n",
    "    with rio.open(reprojected_raster_path) as src:\n",
    "        for idx, row in tqdm(grids_gdf.iterrows(), total=len(grids_gdf)):\n",
    "            try:\n",
    "                mask, transform = rio.mask.mask(src, [row['geometry']], crop=True)\n",
    "                unique_vals = np.unique(mask)\n",
    "                if len(unique_vals) <= 1:  # Only background or no-data\n",
    "                    print(f\"Zone {row['id']} skipped: {unique_vals}\")\n",
    "                    continue\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Zone {row['id']} caused error: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Filter the GeoDataFrame\n",
    "    grids_gdf_valid = grids_gdf.loc[valid_indices].copy()\n",
    "\n",
    "    # Create ZonalAnalysis object for computing crop metrics per grid zone\n",
    "    za = pls.ZonalAnalysis(\n",
    "        reprojected_raster_path,  # Use the reprojected raster\n",
    "        zones=grids_gdf_valid,\n",
    "        zone_index='id',\n",
    "        neighborhood_rule=8       # 8-neighbor connectivity for landscape pattern analysis\n",
    "    )\n",
    "\n",
    "    # Compute class-level metrics (per crop type) for each zone\n",
    "    class_metrics_df = za.compute_class_metrics_df().reset_index()\n",
    "    class_metrics_df.to_csv(os.path.join(os.path.dirname(OUT_DIR), f'crop_class_metrics_{year}.csv'), index=False)\n",
    "\n",
    "    # Compute landscape-level metrics (overall structure) for each zone\n",
    "    landscape_metrics_df = za.compute_landscape_metrics_df().reset_index()\n",
    "    landscape_metrics_df.to_csv(os.path.join(os.path.dirname(OUT_DIR), f'crop_landscape_metrics_{year}.csv'), index=False)\n",
    "\n",
    "print('Crop metrics computation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954e882",
   "metadata": {},
   "source": [
    "## Compute Crop Intensity Using Rasterstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to crop mask\n",
    "crop_file_path = os.path.join(MAIN_DATA_DIR, 'DE_Crop_Types_2017_2021', f'{CROP}_mask_combined.tif')\n",
    "\n",
    "# Collect valid zone indices\n",
    "valid_indices = []\n",
    "\n",
    "with rio.open(crop_file_path) as src:\n",
    "    for idx, row in tqdm(grids_gdf.iterrows(), total=len(grids_gdf)):\n",
    "        try:\n",
    "            mask, transform = rio.mask.mask(src, [row['geometry']], crop=True)\n",
    "            unique_vals = np.unique(mask)\n",
    "            if len(unique_vals) <= 1:  # Only background or no-data\n",
    "                print(f\"Zone {row['id']} skipped: {unique_vals}\")\n",
    "                continue\n",
    "            valid_indices.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Zone {row['id']} caused error: {e}\")\n",
    "            continue\n",
    "\n",
    "# Filter the GeoDataFrame\n",
    "grids_gdf_valid = grids_gdf.loc[valid_indices].copy()\n",
    "\n",
    "# Calculate zonal stats\n",
    "stats = zonal_stats(grids_gdf_valid, crop_file_path, stats=[\"mean\"])\n",
    "\n",
    "# Add results to GeoDataFrame\n",
    "zones_stats = grids_gdf_valid.copy()\n",
    "for key in stats[0].keys():\n",
    "    zones_stats[key] = [s[key] for s in stats]\n",
    "\n",
    "zones_stats.rename(columns={\"mean\": 'crop_intensity'}, inplace=True)\n",
    "zones_stats['normalized_crop_intensity'] = zones_stats['crop_intensity'] / 5\n",
    "zones_stats = zones_stats[['id', 'geometry', 'crop_intensity', 'normalized_crop_intensity']]\n",
    "\n",
    "# Save the data\n",
    "zones_stats.to_csv(os.path.join(OUT_DIR, f'crop_intensity.csv'), index=False)\n",
    "print('Crop intensity computation complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
