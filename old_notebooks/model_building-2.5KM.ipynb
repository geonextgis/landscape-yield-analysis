{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04197b24-1c58-464c-aafe-b5ff7b42092e",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e362ef0-5387-4472-8f44-f901829852d2",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bed7982-f109-402d-acc2-42c4ea3f9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from glob import glob\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384cebd-26b9-48e7-aadb-52459104b5c1",
   "metadata": {},
   "source": [
    "## Define Files and Directory Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0e57fa-f2e5-4720-973f-ba03aa2965a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory containing raw raster and vector datasets\n",
    "MAIN_DATA_DIR = r'/beegfs/halder/DATA'\n",
    "\n",
    "# GitHub-linked project directory where processed data and results are stored\n",
    "PROJECT_DATA_DIR = r'/beegfs/halder/GITHUB/RESEARCH/Landscape-Analysis/data'\n",
    "\n",
    "# Temporary directory used for storing intermediate files\n",
    "TEMP_DIR = os.path.join(PROJECT_DATA_DIR, 'TEMP')\n",
    "\n",
    "# Output directory\n",
    "OUT_DIR = os.path.join(PROJECT_DATA_DIR, 'OUTPUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77991d-d221-40f4-9dba-8402f667c467",
   "metadata": {},
   "source": [
    "## Load Hexagonal Grid for Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8109e22a-1c6a-448b-b9d1-467b535308ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grids Shape: (67545, 2)\n",
      "Successfully read the grids!\n"
     ]
    }
   ],
   "source": [
    "# Define the distance and epsg\n",
    "DISTANCE = 2.5\n",
    "EPSG = 25832\n",
    "CROP = 'WW'\n",
    "CROP_CODE = 1110\n",
    "\n",
    "# Path to grid shapefile\n",
    "GRID_PATH = os.path.join(PROJECT_DATA_DIR, 'VECTOR', f'DE_Hexbins_{DISTANCE}sqkm_EPSG_{EPSG}.shp')\n",
    "\n",
    "# Load grid as a GeoDataFrame and retain relevant columns\n",
    "grids_gdf = gpd.read_file(GRID_PATH)\n",
    "grids_gdf = grids_gdf[['id', 'geometry']]\n",
    "grids_gdf['id'] = grids_gdf['id'].astype(int)\n",
    "\n",
    "print('Grids Shape:', grids_gdf.shape)\n",
    "print('Successfully read the grids!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620568b5-e9e8-48e5-80fb-97cf7e7e368e",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1fcb90-fc81-4764-b3cf-1b2f9bfc57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151795, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>year</th>\n",
       "      <th>landscape_shannon_diversity_index</th>\n",
       "      <th>landscape_patch_density</th>\n",
       "      <th>landscape_euclidean_nearest_neighbor_mn</th>\n",
       "      <th>productive_prop_landscape</th>\n",
       "      <th>productive_patch_density</th>\n",
       "      <th>productive_edge_density</th>\n",
       "      <th>productive_shape_index</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>tmin_std</th>\n",
       "      <th>tmax_max</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmax_std</th>\n",
       "      <th>rad_min</th>\n",
       "      <th>rad_max</th>\n",
       "      <th>rad_mean</th>\n",
       "      <th>rad_std</th>\n",
       "      <th>distributed_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177</td>\n",
       "      <td>DEA29</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.275164</td>\n",
       "      <td>50.633356</td>\n",
       "      <td>35.429559</td>\n",
       "      <td>63.120532</td>\n",
       "      <td>17.000981</td>\n",
       "      <td>103.266872</td>\n",
       "      <td>11.399003</td>\n",
       "      <td>...</td>\n",
       "      <td>6.474413</td>\n",
       "      <td>5.301266</td>\n",
       "      <td>31.350</td>\n",
       "      <td>13.942030</td>\n",
       "      <td>7.335970</td>\n",
       "      <td>1.76025</td>\n",
       "      <td>30.20350</td>\n",
       "      <td>9.949048</td>\n",
       "      <td>7.644765</td>\n",
       "      <td>9.660467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>DEA29</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.275164</td>\n",
       "      <td>50.633356</td>\n",
       "      <td>35.429559</td>\n",
       "      <td>63.120532</td>\n",
       "      <td>17.000981</td>\n",
       "      <td>103.266872</td>\n",
       "      <td>11.399003</td>\n",
       "      <td>...</td>\n",
       "      <td>6.452189</td>\n",
       "      <td>5.814843</td>\n",
       "      <td>34.225</td>\n",
       "      <td>14.195707</td>\n",
       "      <td>7.247160</td>\n",
       "      <td>1.75925</td>\n",
       "      <td>29.85350</td>\n",
       "      <td>10.030397</td>\n",
       "      <td>7.199292</td>\n",
       "      <td>8.783925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>DEA29</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.275164</td>\n",
       "      <td>50.633356</td>\n",
       "      <td>35.429559</td>\n",
       "      <td>63.120532</td>\n",
       "      <td>17.000981</td>\n",
       "      <td>103.266872</td>\n",
       "      <td>11.399003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.692172</td>\n",
       "      <td>6.386867</td>\n",
       "      <td>35.550</td>\n",
       "      <td>14.497307</td>\n",
       "      <td>8.406264</td>\n",
       "      <td>1.75925</td>\n",
       "      <td>28.26050</td>\n",
       "      <td>11.004956</td>\n",
       "      <td>8.078055</td>\n",
       "      <td>8.787525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>DEA29</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.275164</td>\n",
       "      <td>50.633356</td>\n",
       "      <td>35.429559</td>\n",
       "      <td>63.120532</td>\n",
       "      <td>17.000981</td>\n",
       "      <td>103.266872</td>\n",
       "      <td>11.399003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.100421</td>\n",
       "      <td>5.369863</td>\n",
       "      <td>30.750</td>\n",
       "      <td>13.312290</td>\n",
       "      <td>7.010546</td>\n",
       "      <td>1.75925</td>\n",
       "      <td>28.94000</td>\n",
       "      <td>10.089957</td>\n",
       "      <td>7.322121</td>\n",
       "      <td>8.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>DEA29</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.275164</td>\n",
       "      <td>50.633356</td>\n",
       "      <td>35.429559</td>\n",
       "      <td>63.120532</td>\n",
       "      <td>17.000981</td>\n",
       "      <td>103.266872</td>\n",
       "      <td>11.399003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.644631</td>\n",
       "      <td>6.005391</td>\n",
       "      <td>33.750</td>\n",
       "      <td>13.636912</td>\n",
       "      <td>8.237541</td>\n",
       "      <td>1.76325</td>\n",
       "      <td>29.40525</td>\n",
       "      <td>10.146389</td>\n",
       "      <td>7.633380</td>\n",
       "      <td>9.065824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id NUTS_ID  year  landscape_shannon_diversity_index  \\\n",
       "0  177   DEA29  2001                           1.275164   \n",
       "1  177   DEA29  2002                           1.275164   \n",
       "2  177   DEA29  2003                           1.275164   \n",
       "3  177   DEA29  2004                           1.275164   \n",
       "4  177   DEA29  2005                           1.275164   \n",
       "\n",
       "   landscape_patch_density  landscape_euclidean_nearest_neighbor_mn  \\\n",
       "0                50.633356                                35.429559   \n",
       "1                50.633356                                35.429559   \n",
       "2                50.633356                                35.429559   \n",
       "3                50.633356                                35.429559   \n",
       "4                50.633356                                35.429559   \n",
       "\n",
       "   productive_prop_landscape  productive_patch_density  \\\n",
       "0                  63.120532                 17.000981   \n",
       "1                  63.120532                 17.000981   \n",
       "2                  63.120532                 17.000981   \n",
       "3                  63.120532                 17.000981   \n",
       "4                  63.120532                 17.000981   \n",
       "\n",
       "   productive_edge_density  productive_shape_index  ...  tmin_mean  tmin_std  \\\n",
       "0               103.266872               11.399003  ...   6.474413  5.301266   \n",
       "1               103.266872               11.399003  ...   6.452189  5.814843   \n",
       "2               103.266872               11.399003  ...   5.692172  6.386867   \n",
       "3               103.266872               11.399003  ...   5.100421  5.369863   \n",
       "4               103.266872               11.399003  ...   5.644631  6.005391   \n",
       "\n",
       "   tmax_max  tmax_mean  tmax_std  rad_min   rad_max   rad_mean   rad_std  \\\n",
       "0    31.350  13.942030  7.335970  1.76025  30.20350   9.949048  7.644765   \n",
       "1    34.225  14.195707  7.247160  1.75925  29.85350  10.030397  7.199292   \n",
       "2    35.550  14.497307  8.406264  1.75925  28.26050  11.004956  8.078055   \n",
       "3    30.750  13.312290  7.010546  1.75925  28.94000  10.089957  7.322121   \n",
       "4    33.750  13.636912  8.237541  1.76325  29.40525  10.146389  7.633380   \n",
       "\n",
       "   distributed_yield  \n",
       "0           9.660467  \n",
       "1           8.783925  \n",
       "2           8.787525  \n",
       "3           8.694622  \n",
       "4           9.065824  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data for model training\n",
    "data = pd.read_csv(os.path.join(OUT_DIR, f'Landscape_Data_{DISTANCE}KM.csv'))\n",
    "\n",
    "# Drop the geometry column\n",
    "data.drop(columns=['geometry'], inplace=True)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863469e0-3c7c-4260-a6e8-334384f9cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7355, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_ID</th>\n",
       "      <th>year</th>\n",
       "      <th>landscape_shannon_diversity_index</th>\n",
       "      <th>landscape_patch_density</th>\n",
       "      <th>landscape_euclidean_nearest_neighbor_mn</th>\n",
       "      <th>productive_prop_landscape</th>\n",
       "      <th>productive_patch_density</th>\n",
       "      <th>productive_edge_density</th>\n",
       "      <th>productive_shape_index</th>\n",
       "      <th>productive_enn_mn</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>tmin_std</th>\n",
       "      <th>tmax_max</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmax_std</th>\n",
       "      <th>rad_min</th>\n",
       "      <th>rad_max</th>\n",
       "      <th>rad_mean</th>\n",
       "      <th>rad_std</th>\n",
       "      <th>distributed_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE111</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.133976</td>\n",
       "      <td>91.081012</td>\n",
       "      <td>40.694999</td>\n",
       "      <td>58.959762</td>\n",
       "      <td>32.306092</td>\n",
       "      <td>123.813543</td>\n",
       "      <td>14.933838</td>\n",
       "      <td>36.269269</td>\n",
       "      <td>...</td>\n",
       "      <td>5.462172</td>\n",
       "      <td>5.626520</td>\n",
       "      <td>32.204076</td>\n",
       "      <td>13.642001</td>\n",
       "      <td>7.579564</td>\n",
       "      <td>2.123588</td>\n",
       "      <td>30.559248</td>\n",
       "      <td>10.904269</td>\n",
       "      <td>8.337542</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE111</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.133976</td>\n",
       "      <td>91.081012</td>\n",
       "      <td>40.694999</td>\n",
       "      <td>58.959762</td>\n",
       "      <td>32.306092</td>\n",
       "      <td>123.813543</td>\n",
       "      <td>14.933838</td>\n",
       "      <td>36.269269</td>\n",
       "      <td>...</td>\n",
       "      <td>4.649203</td>\n",
       "      <td>7.078542</td>\n",
       "      <td>35.685532</td>\n",
       "      <td>13.398965</td>\n",
       "      <td>8.574135</td>\n",
       "      <td>2.124509</td>\n",
       "      <td>30.031833</td>\n",
       "      <td>11.370202</td>\n",
       "      <td>7.933198</td>\n",
       "      <td>6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE111</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.133976</td>\n",
       "      <td>91.081012</td>\n",
       "      <td>40.694999</td>\n",
       "      <td>58.959762</td>\n",
       "      <td>32.306092</td>\n",
       "      <td>123.813543</td>\n",
       "      <td>14.933838</td>\n",
       "      <td>36.269269</td>\n",
       "      <td>...</td>\n",
       "      <td>5.066559</td>\n",
       "      <td>7.391742</td>\n",
       "      <td>35.123403</td>\n",
       "      <td>14.172588</td>\n",
       "      <td>9.497394</td>\n",
       "      <td>2.123687</td>\n",
       "      <td>30.656636</td>\n",
       "      <td>11.779034</td>\n",
       "      <td>8.297264</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE111</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.133976</td>\n",
       "      <td>91.081012</td>\n",
       "      <td>40.694999</td>\n",
       "      <td>58.959762</td>\n",
       "      <td>32.306092</td>\n",
       "      <td>123.813543</td>\n",
       "      <td>14.933838</td>\n",
       "      <td>36.269269</td>\n",
       "      <td>...</td>\n",
       "      <td>3.812845</td>\n",
       "      <td>5.956027</td>\n",
       "      <td>31.172983</td>\n",
       "      <td>12.510505</td>\n",
       "      <td>8.002659</td>\n",
       "      <td>2.124509</td>\n",
       "      <td>30.555884</td>\n",
       "      <td>11.297833</td>\n",
       "      <td>7.824148</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE111</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.133976</td>\n",
       "      <td>91.081012</td>\n",
       "      <td>40.694999</td>\n",
       "      <td>58.959762</td>\n",
       "      <td>32.306092</td>\n",
       "      <td>123.813543</td>\n",
       "      <td>14.933838</td>\n",
       "      <td>36.269269</td>\n",
       "      <td>...</td>\n",
       "      <td>3.947408</td>\n",
       "      <td>7.160355</td>\n",
       "      <td>34.336317</td>\n",
       "      <td>12.500369</td>\n",
       "      <td>9.350449</td>\n",
       "      <td>2.123588</td>\n",
       "      <td>31.302025</td>\n",
       "      <td>10.924573</td>\n",
       "      <td>8.076493</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUTS_ID  year  landscape_shannon_diversity_index  landscape_patch_density  \\\n",
       "0   DE111  2001                           1.133976                91.081012   \n",
       "1   DE111  2002                           1.133976                91.081012   \n",
       "2   DE111  2003                           1.133976                91.081012   \n",
       "3   DE111  2004                           1.133976                91.081012   \n",
       "4   DE111  2005                           1.133976                91.081012   \n",
       "\n",
       "   landscape_euclidean_nearest_neighbor_mn  productive_prop_landscape  \\\n",
       "0                                40.694999                  58.959762   \n",
       "1                                40.694999                  58.959762   \n",
       "2                                40.694999                  58.959762   \n",
       "3                                40.694999                  58.959762   \n",
       "4                                40.694999                  58.959762   \n",
       "\n",
       "   productive_patch_density  productive_edge_density  productive_shape_index  \\\n",
       "0                 32.306092               123.813543               14.933838   \n",
       "1                 32.306092               123.813543               14.933838   \n",
       "2                 32.306092               123.813543               14.933838   \n",
       "3                 32.306092               123.813543               14.933838   \n",
       "4                 32.306092               123.813543               14.933838   \n",
       "\n",
       "   productive_enn_mn  ...  tmin_mean  tmin_std   tmax_max  tmax_mean  \\\n",
       "0          36.269269  ...   5.462172  5.626520  32.204076  13.642001   \n",
       "1          36.269269  ...   4.649203  7.078542  35.685532  13.398965   \n",
       "2          36.269269  ...   5.066559  7.391742  35.123403  14.172588   \n",
       "3          36.269269  ...   3.812845  5.956027  31.172983  12.510505   \n",
       "4          36.269269  ...   3.947408  7.160355  34.336317  12.500369   \n",
       "\n",
       "   tmax_std   rad_min    rad_max   rad_mean   rad_std  distributed_yield  \n",
       "0  7.579564  2.123588  30.559248  10.904269  8.337542               6.05  \n",
       "1  8.574135  2.124509  30.031833  11.370202  7.933198               6.79  \n",
       "2  9.497394  2.123687  30.656636  11.779034  8.297264               5.87  \n",
       "3  8.002659  2.124509  30.555884  11.297833  7.824148               7.68  \n",
       "4  9.350449  2.123588  31.302025  10.924573  8.076493               7.44  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra processing\n",
    "data = data.drop(columns=['id']).groupby(by=['NUTS_ID', 'year']).mean().reset_index()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a512cd-c293-4883-b382-8a523532599d",
   "metadata": {},
   "source": [
    "## Leave-Location-and-Time-Out with Moving Window (LLTO-MW) Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d9fe69-8365-4ab9-a1fb-382d50f16d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_location_and_time_out_moving_window(\n",
    "    data,\n",
    "    year_col,\n",
    "    space_col,\n",
    "    train_years=10,\n",
    "    test_years=1,\n",
    "    test_frac=0.3,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Leave-Location-and-Time-Out with Moving Window (LLTO-MW)\n",
    "\n",
    "    Implements a generalized LLTO cross-validation strategy:\n",
    "    - Trains on a moving window of fixed training years\n",
    "    - Leaves out a random 30% of locations for testing in the next test_year(s)\n",
    "    \n",
    "    Each split:\n",
    "    - Trains on `train_years` using 70% of locations\n",
    "    - Tests on the immediately following `test_years` using the remaining 30% of locations\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Input dataframe containing temporal and spatial columns.\n",
    "    year_col : str\n",
    "        Column name representing the year (int or datetime).\n",
    "    space_col : str\n",
    "        Column name representing the spatial unit (e.g., district, grid).\n",
    "    train_years : int, default=10\n",
    "        Number of consecutive years to use for training.\n",
    "    test_years : int, default=1\n",
    "        Number of consecutive years to use for testing (after training window).\n",
    "    test_frac : float, default=0.3\n",
    "        Fraction of locations to leave out for testing.\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility of location sampling.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    splits : list of (train_indices, test_indices)\n",
    "        Index tuples for training and testing data in each LLTO-MW fold.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    splits = []\n",
    "\n",
    "    all_years = sorted(data[year_col].unique())\n",
    "    all_locations = np.array(data[space_col].unique())\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "\n",
    "    print(\"\\nLeave-Location-and-Time-Out with Moving Window (LLTO-MW)\\n\" + \"-\" * 60)\n",
    "\n",
    "    for start_idx in range(len(all_years) - train_years - test_years + 1):\n",
    "        train_year_start = all_years[start_idx]\n",
    "        train_year_end = all_years[start_idx + train_years - 1]\n",
    "        test_year_start = all_years[start_idx + train_years]\n",
    "        test_year_end = test_year_start + test_years - 1\n",
    "\n",
    "        # Random 70-30 location split\n",
    "        shuffled_locations = rng.permutation(all_locations)\n",
    "        split_idx = int((1 - test_frac) * len(shuffled_locations))\n",
    "        train_locs = shuffled_locations[:split_idx]\n",
    "        test_locs = shuffled_locations[split_idx:]\n",
    "\n",
    "        train_mask = (\n",
    "            data[year_col].between(train_year_start, train_year_end) &\n",
    "            data[space_col].isin(train_locs)\n",
    "        )\n",
    "        test_mask = (\n",
    "            data[year_col].between(test_year_start, test_year_end) &\n",
    "            data[space_col].isin(test_locs)\n",
    "        )\n",
    "\n",
    "        train_idx = data[train_mask].index\n",
    "        test_idx = data[test_mask].index\n",
    "\n",
    "        if len(train_idx) > 0 and len(test_idx) > 0:\n",
    "            splits.append((list(train_idx), list(test_idx)))\n",
    "            print(f\"Train: {train_year_start}-{train_year_end} | Test: {test_year_start}-{test_year_end} | \"\n",
    "                  f\"Train Locs: {len(train_locs)} | Test Locs: {len(test_locs)} \"\n",
    "                  f\"({len(train_idx)} train, {len(test_idx)} test)\")\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37fdef66-02f0-4974-9b42-2d4c5a5752e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scale_train_test(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Applies RobustScaler to train and test DataFrames based on train data statistics.\n",
    "    NaN values are ignored during fitting and preserved in output.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df (pd.DataFrame): Training dataset\n",
    "    - test_df (pd.DataFrame): Testing dataset\n",
    "\n",
    "    Returns:\n",
    "    - scaled_train (pd.DataFrame): Robust-scaled training data\n",
    "    - scaled_test (pd.DataFrame): Robust-scaled test data\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    # Fit only on non-NaN values in training data\n",
    "    scaler.fit(train_df.dropna())\n",
    "\n",
    "    # Transform while preserving original index and column names\n",
    "    scaled_train = pd.DataFrame(\n",
    "        scaler.transform(train_df),\n",
    "        index=train_df.index,\n",
    "        columns=train_df.columns\n",
    "    )\n",
    "\n",
    "    scaled_test = pd.DataFrame(\n",
    "        scaler.transform(test_df),\n",
    "        index=test_df.index,\n",
    "        columns=test_df.columns\n",
    "    )\n",
    "\n",
    "    # Preserve original NaN values\n",
    "    scaled_train[train_df.isna()] = pd.NA\n",
    "    scaled_test[test_df.isna()] = pd.NA\n",
    "\n",
    "    return scaled_train, scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7e70c7-1b26-4a46-a76d-8e526b313765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leave-Location-and-Time-Out with Moving Window (LLTO-MW)\n",
      "------------------------------------------------------------\n",
      "Train: 2001-2010 | Test: 2011-2011 | Train Locs: 250 | Test Locs: 108 (2400 train, 103 test)\n",
      "Train: 2002-2011 | Test: 2012-2012 | Train Locs: 250 | Test Locs: 108 (2406 train, 100 test)\n",
      "Train: 2003-2012 | Test: 2013-2013 | Train Locs: 250 | Test Locs: 108 (2399 train, 98 test)\n",
      "Train: 2004-2013 | Test: 2014-2014 | Train Locs: 250 | Test Locs: 108 (2391 train, 101 test)\n",
      "Train: 2005-2014 | Test: 2015-2015 | Train Locs: 250 | Test Locs: 108 (2401 train, 95 test)\n",
      "Train: 2006-2015 | Test: 2016-2016 | Train Locs: 250 | Test Locs: 108 (2344 train, 97 test)\n",
      "Train: 2007-2016 | Test: 2017-2017 | Train Locs: 250 | Test Locs: 108 (2309 train, 90 test)\n",
      "Train: 2008-2017 | Test: 2018-2018 | Train Locs: 250 | Test Locs: 108 (2275 train, 88 test)\n",
      "Train: 2009-2018 | Test: 2019-2019 | Train Locs: 250 | Test Locs: 108 (2250 train, 83 test)\n",
      "Train: 2010-2019 | Test: 2020-2020 | Train Locs: 250 | Test Locs: 108 (2215 train, 81 test)\n",
      "Train: 2011-2020 | Test: 2021-2021 | Train Locs: 250 | Test Locs: 108 (2179 train, 79 test)\n",
      "Train: 2012-2021 | Test: 2022-2022 | Train Locs: 250 | Test Locs: 108 (2128 train, 78 test)\n",
      "Train: 2013-2022 | Test: 2023-2023 | Train Locs: 250 | Test Locs: 108 (2021 train, 89 test)\n"
     ]
    }
   ],
   "source": [
    "# Extract the group index\n",
    "group_index = leave_location_and_time_out_moving_window(\n",
    "    data=data, \n",
    "    year_col='year',\n",
    "    space_col='NUTS_ID',\n",
    "    train_years=10,\n",
    "    test_years=1,\n",
    "    test_frac=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define the columns to be droppend from 'X'\n",
    "# cols_to_be_dropped = ['id', 'NUTS_ID', 'year', 'distributed_yield']\n",
    "cols_to_be_dropped = ['NUTS_ID', 'year', 'distributed_yield']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4d37b-798b-4240-a873-5422b50355f5",
   "metadata": {},
   "source": [
    "## XGBoost Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc259a4-1d94-4113-bbfc-47487008f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 20),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 1.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 0.001, 5),\n",
    "        \"subsample\": trial.suggest_loguniform(\"subsample\", 0.1, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_loguniform(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 10),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 10)\n",
    "    }\n",
    "\n",
    "    # Log trial parameters\n",
    "    logger.info(f\"\\n\\n\\nTrial {trial.number} - Params: {params}\")\n",
    "\n",
    "    model = XGBRegressor(**params, tree_method=\"hist\", predictor=\"gpu_predictor\", device=\"cuda\")\n",
    "    \n",
    "    losses = []\n",
    "    for fold, (train_index, test_index) in enumerate(group_index):\n",
    "        X_train = data.loc[train_index].drop(cols_to_be_dropped, axis=1)\n",
    "        y_train = data.loc[train_index]['distributed_yield']\n",
    "\n",
    "        X_test = data.loc[test_index].drop(cols_to_be_dropped, axis=1)\n",
    "        y_test = data.loc[test_index]['distributed_yield']\n",
    "\n",
    "        # Standardize the data\n",
    "        X_train_scaled, X_test_scaled = robust_scale_train_test(X_train, X_test)\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        test_preds = model.predict(X_test_scaled)\n",
    "\n",
    "        # Calculate RMSE loss on the current test set\n",
    "        loss = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Log fold results\n",
    "        logger.info(f\"\\tFold {fold}, Test MSE: {loss:.4f}\")\n",
    "        \n",
    "    # Calculate average loss over all folds\n",
    "    average_loss = np.mean(losses)\n",
    "\n",
    "    # Log final trial result\n",
    "    logger.info(f\"\\tTrial {trial.number} - Average Test RMSE: {average_loss:.4f}\\n\")\n",
    "\n",
    "    # Return the average score\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04c4ae65-7ffc-44af-92ac-43bdea270ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fff8fe908914b8f979a656aceac6545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 17:41:07,118] Trial 0 finished with value: 25864887570.14415 and parameters: {'max_depth': 10, 'learning_rate': 0.7969454818643931, 'n_estimators': 746, 'min_child_weight': 6, 'gamma': 0.003776663327107336, 'subsample': 0.14321698289111517, 'colsample_bytree': 0.1143098387631322, 'reg_alpha': 2.1423021757741068, 'reg_lambda': 0.10129197956845731}. Best is trial 0 with value: 25864887570.14415.\n",
      "[I 2025-06-24 17:41:33,357] Trial 1 finished with value: 0.9797308275507576 and parameters: {'max_depth': 16, 'learning_rate': 0.010994335574766204, 'n_estimators': 972, 'min_child_weight': 9, 'gamma': 0.00610149136730271, 'subsample': 0.1519934830130981, 'colsample_bytree': 0.1525472945805261, 'reg_alpha': 0.0033205591037519565, 'reg_lambda': 0.042051564509138675}. Best is trial 1 with value: 0.9797308275507576.\n",
      "[I 2025-06-24 17:41:56,235] Trial 2 finished with value: 0.9901563523829773 and parameters: {'max_depth': 11, 'learning_rate': 0.038234752246751866, 'n_estimators': 631, 'min_child_weight': 2, 'gamma': 0.012040216379191714, 'subsample': 0.23246728489504342, 'colsample_bytree': 0.2858051065806936, 'reg_alpha': 0.8431013932082461, 'reg_lambda': 0.0009962513222055108}. Best is trial 1 with value: 0.9797308275507576.\n",
      "[I 2025-06-24 17:41:58,690] Trial 3 finished with value: 1.0188230053080696 and parameters: {'max_depth': 12, 'learning_rate': 0.15304852121831464, 'n_estimators': 94, 'min_child_weight': 7, 'gamma': 0.0042733023193754, 'subsample': 0.11615865989246456, 'colsample_bytree': 0.8889667907018928, 'reg_alpha': 6.732248920775331, 'reg_lambda': 1.1015056790269626}. Best is trial 1 with value: 0.9797308275507576.\n",
      "[I 2025-06-24 17:42:17,165] Trial 4 finished with value: 0.9752437674275971 and parameters: {'max_depth': 9, 'learning_rate': 0.015679933916723017, 'n_estimators': 700, 'min_child_weight': 5, 'gamma': 0.002827585657311758, 'subsample': 0.3127353036780371, 'colsample_bytree': 0.10824018381500958, 'reg_alpha': 3.5204810455260365, 'reg_lambda': 0.0019674328025306126}. Best is trial 4 with value: 0.9752437674275971.\n",
      "[I 2025-06-24 17:42:34,946] Trial 5 finished with value: 0.9828275441043215 and parameters: {'max_depth': 15, 'learning_rate': 0.0420167205437253, 'n_estimators': 544, 'min_child_weight': 6, 'gamma': 0.0048280425192712886, 'subsample': 0.9323621351781477, 'colsample_bytree': 0.5958443469672517, 'reg_alpha': 4.9830438374949075, 'reg_lambda': 2.9794544625913595}. Best is trial 4 with value: 0.9752437674275971.\n",
      "[I 2025-06-24 17:42:43,211] Trial 6 finished with value: 7.27458660796542 and parameters: {'max_depth': 14, 'learning_rate': 0.697828126512603, 'n_estimators': 134, 'min_child_weight': 2, 'gamma': 0.0014699223219374884, 'subsample': 0.21150972021685588, 'colsample_bytree': 0.24472440973990114, 'reg_alpha': 0.002273762810253686, 'reg_lambda': 1.3921548533046495}. Best is trial 4 with value: 0.9752437674275971.\n",
      "[I 2025-06-24 17:42:52,954] Trial 7 finished with value: 0.9972376187370896 and parameters: {'max_depth': 10, 'learning_rate': 0.036464395589807214, 'n_estimators': 566, 'min_child_weight': 2, 'gamma': 0.9274757630456326, 'subsample': 0.11872731425335903, 'colsample_bytree': 0.9702573394120726, 'reg_alpha': 0.7264803074826727, 'reg_lambda': 0.0009853225172032562}. Best is trial 4 with value: 0.9752437674275971.\n",
      "[I 2025-06-24 17:43:02,079] Trial 8 finished with value: 3.0562193219664784 and parameters: {'max_depth': 4, 'learning_rate': 0.4274869455295215, 'n_estimators': 722, 'min_child_weight': 8, 'gamma': 0.7126985539523761, 'subsample': 0.11858906685575266, 'colsample_bytree': 0.2282788775990513, 'reg_alpha': 0.00037961668958008145, 'reg_lambda': 2.0678409397839492}. Best is trial 4 with value: 0.9752437674275971.\n",
      "[I 2025-06-24 17:43:07,803] Trial 9 finished with value: 0.9735386037106062 and parameters: {'max_depth': 14, 'learning_rate': 0.045898241814956484, 'n_estimators': 110, 'min_child_weight': 4, 'gamma': 0.015953036325173326, 'subsample': 0.5365450324352024, 'colsample_bytree': 0.4340677011889399, 'reg_alpha': 2.7293781650374753, 'reg_lambda': 0.022965432344634346}. Best is trial 9 with value: 0.9735386037106062.\n"
     ]
    }
   ],
   "source": [
    "# Configure logging to save logs with timestamps\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(OUT_DIR, f\"xgboost_{DISTANCE}KM_NUTS.log\"),  # Log file name\n",
    "    level=logging.INFO,  # Capture detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Includes timestamp\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",  # Custom timestamp format\n",
    "    filemode=\"w\"  # \"w\" = overwrite each run, use \"a\" to append\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "optuna.logging.enable_propagation()  # Propagate logs to the root logger.\n",
    "optuna.logging.disable_default_handler()  # Stop showing logs in sys.stderr.\n",
    "\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"xgboost\", sampler=sampler, direction=\"minimize\")\n",
    "\n",
    "logger.info(\"Start optimization.\")\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
